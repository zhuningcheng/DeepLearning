{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e9699ab-8238-40c2-b986-84747698d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本代码构建了AlexNet卷积神经网络，并使用CIFAR10数据集进行训练完成识别任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "94d0d43d-fe79-4ee7-a2c7-35651a6adb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "376395b3-ccc7-404b-b03e-bc28b263a13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# 运算设备设置为显卡\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c15b2bf8-8e0f-4a92-8ae4-d14a9bc02cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 170M/170M [03:32<00:00, 803kB/s]\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 调整到AlexNet需要的尺寸\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10('data', \n",
    "                                        train=True, \n",
    "                                        transform=transform, \n",
    "                                        download=True)\n",
    "test_set = torchvision.datasets.CIFAR10('data', \n",
    "                                       train=False, \n",
    "                                       transform=transform, \n",
    "                                       download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2a96d679-955d-4f8f-9cff-6869d3fcb00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置批次大小\n",
    "BATCH_SIZE= 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "09607be8-0f50-4728-b022-f855e50062d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练集和测试集\n",
    "train_loader = data.DataLoader(training_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = data.DataLoader(test_set, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a7c57d5c-349e-4be7-8786-745b7a2bd275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义AlexNet网络架构\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        # 卷积部分\n",
    "        self.c1 = nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.s2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.c3 = nn.Conv2d(96, 256, kernel_size=5, padding=2)\n",
    "        self.s4 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.c5 = nn.Conv2d(256, 384, kernel_size=3, padding=1)\n",
    "        self.c6 = nn.Conv2d(384, 384, kernel_size=3, padding=1)\n",
    "        self.c7 = nn.Conv2d(384, 256, kernel_size=3, padding=1)\n",
    "        self.s8 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.flatten = nn.Flatten()\n",
    "        # 全连接部分\n",
    "        self.f1 = nn.Linear(256 * 6 * 6, 4096)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.f2 = nn.Linear(4096, 4096)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.f3 = nn.Linear(4096, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.c1(x))\n",
    "        x = self.s2(x)\n",
    "        x = self.relu(self.c3(x))\n",
    "        x = self.s4(x)\n",
    "        x = self.relu(self.c5(x))\n",
    "        x = self.relu(self.c6(x))\n",
    "        x = self.relu(self.c7(x))\n",
    "        x = self.s8(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.f1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(self.f2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.f3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7eefd379-fbb2-44b7-8d84-6614f0db07d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (c1): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "  (relu): ReLU()\n",
       "  (s2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (c3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (s4): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (c5): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (c6): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (c7): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (s8): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (adaptive_pool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (f1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (f2): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (f3): Linear(in_features=4096, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将模型移送到GPU内存中\n",
    "model = AlexNet()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6600e52b-90ed-4545-8919-f8a967dedfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置损失函数\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "# 设置学习率\n",
    "lr = 0.01\n",
    "# 设置优化方法\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e81e5746-dd3c-4920-9191-b3a51a46bee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设定训练轮次\n",
    "EPOCH = 5\n",
    "# 记录训练准确度的历史\n",
    "train_acc_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f519e53-6862-4a98-904b-9b13de1b8411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练\n",
    "for epoch in range(EPOCH):\n",
    "    training_loss = 0.0\n",
    "    training_acc = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(train_loader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_func(pred, y)\n",
    "\n",
    "        # 清除梯度，否则会将每一个batch的梯度累加\n",
    "        optimizer.zero_grad()\n",
    "        # 反向传播(计算梯度)\n",
    "        loss.backward()\n",
    "        # 更新位置参数的值\n",
    "        optimizer.step()\n",
    "\n",
    "        training_loss += loss.item()\n",
    "        training_acc += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    training_acc /= len(train_loader.dataset)\n",
    "    training_loss /= len(train_loader)\n",
    "\n",
    "    train_acc_history.append(training_acc)  # 记录训练准确度\n",
    "    print(f'Epoch {epoch + 1}: training accuracy: {training_acc:4f}, training loss: {training_loss:4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c1c046-a3e3-4375-91f1-bf20f0cd6144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型测试\n",
    "test_loss = 0.0\n",
    "test_acc = 0.0\n",
    "for batch, (X, y) in enumerate(test_loader):\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "    pred = model(X)\n",
    "    loss = loss_func(pred, y)\n",
    "    test_loss += loss.item()\n",
    "    test_acc += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "test_acc /= len(test_loader.dataset)\n",
    "test_loss /= len(test_loader)\n",
    "print(f'test accuracy: {test_acc:4f}', end=', ')\n",
    "print(f'test loss: {test_loss:4f}')\n",
    "\n",
    "# 绘制训练准确度随轮次变化的图\n",
    "# plt.plot(range(1, EPOCH+1), train_acc_history, marker='o', color='b', label='Max Pooling - Accuracy')\n",
    "plt.plot(range(1, EPOCH+1), train_acc_history, marker='o', color='g', label='Avg Pooling - Accuracy')\n",
    "# plt.plot(range(1, EPOCH+1), train_acc_history, marker='o', color='r', label='Min Pooling - Accuracy')\n",
    "\n",
    "plt.title('Training Accuracy over Epochs with Avg Pooling Methods')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
